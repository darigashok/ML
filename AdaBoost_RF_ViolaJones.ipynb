{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3waVN3_eyd42"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import tree\n",
        "from time import time\n",
        "\n",
        "from skimage.transform import integral_image\n",
        "from skimage.feature import haar_like_feature   \n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX5qmlcJz6vS",
        "outputId": "5c1090e7-aa33-45c8-a6a1-d7a0a6ccff08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBBWVZBTDw_Y"
      },
      "outputs": [],
      "source": [
        "train_face = os.listdir('/content/drive/MyDrive/faces/face_train/face')\n",
        "train_face_count = len(train_face)\n",
        "train_non_face = os.listdir('/content/drive/MyDrive/faces/face_train/non-face') \n",
        "train_non_face_count = len(train_face)\n",
        "test_face = os.listdir('/content/drive/MyDrive/faces/face_test/face')\n",
        "test_face_count = len(test_face)\n",
        "test_non_face = os.listdir('/content/drive/MyDrive/faces/face_test/non-face')\n",
        "test_non_face_count = len(test_non_face)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further on the work that supposed to be done with validation set is done with the given test set as there was no way of splitting pgm files into validation and training sets."
      ],
      "metadata": {
        "id": "cgsC7vUvHJxa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta-7Ir8uE902",
        "outputId": "e76e9b0a-4118-484b-bc0a-3cdf0cf8debe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to train features:  988.5846538543701\n"
          ]
        }
      ],
      "source": [
        "DIR=\"/content/drive/MyDrive/faces/face_train\"\n",
        "CAT=[\"face\",\"non-face\"]\n",
        "DIR_TEST = \"/content/drive/MyDrive/faces/face_test\"\n",
        "CAT_TEST = [\"face\", \"non-face\"]\n",
        "training_data=[]\n",
        "feature_types = ['type-2-x', 'type-2-y', 'type-3-x', 'type-4']\n",
        "def init_training_data():\n",
        "    for cat in CAT:\n",
        "        path = os.path.join(DIR, cat)\n",
        "        class_num=CAT.index(cat)\n",
        "        img_path = os.listdir(path)\n",
        "        for img in img_path:\n",
        "            features = []\n",
        "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "            img = np.array(img_array)\n",
        "            img_i = integral_image(img)\n",
        "\n",
        "            features = haar_like_feature(img_i, 0, 0, img_i.shape[1], img_i.shape[0], feature_types)    \n",
        "            training_data.append(features)\n",
        "t_start = time()\n",
        "init_training_data()\n",
        "total_time = time() - t_start\n",
        "print(\"Time to train features: \", total_time)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data = []\n",
        "def init_testing_data():\n",
        "    for cat in CAT_TEST:\n",
        "        path = os.path.join(DIR_TEST, cat)\n",
        "        class_num_test = CAT_TEST.index(cat)\n",
        "        img_path = os.listdir(path)\n",
        "        for img in img_path:\n",
        "            features = []\n",
        "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "            img = np.array(img_array)\n",
        "\n",
        "            img_i = integral_image(img)\n",
        "            try:\n",
        "                features = (haar_like_feature(img_i, 0, 0, img_i.shape[1], img_i.shape[0], feature_types))\n",
        "            except IndexError:\n",
        "                continue      \n",
        "            testing_data.append(features)\n",
        "init_testing_data() "
      ],
      "metadata": {
        "id": "CkAgR6FOz7xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBnt97IVsca8"
      },
      "outputs": [],
      "source": [
        "y_train = np.array([1] * train_face_count + [0] * train_non_face_count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.array([1] * test_face_count + [0] * test_non_face_count) "
      ],
      "metadata": {
        "id": "d46t3Ahr0iPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORTSfpSys7lz"
      },
      "outputs": [],
      "source": [
        "abc = AdaBoostClassifier(n_estimators=10, algorithm=\"SAMME\")\n",
        "t_start = time()\n",
        "model = abc.fit(training_data, y_train)\n",
        "time_adaboost = time() - t_start\n",
        "print(\"Time to train (AdaBoost):\", time_adaboost)\n",
        "\n",
        "y_pred = model.predict(testing_data)\n",
        "print(\"Accuracy (AdaBoost): \", metrics.accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(abc.estimators_)\n",
        "for i in range(len(abc.estimators_)):\n",
        "    print(f\"Tree {i}: \")\n",
        "    print(f\"Weight: {abc.estimator_weights_[i]}\")\n",
        "    print(tree.export_text(abc.estimators_[i]))"
      ],
      "metadata": {
        "id": "t7I2L53_0GEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=10, max_depth=None, max_features=100, n_jobs=-1, random_state=0)\n",
        "t_start = time()\n",
        "rf.fit(training_data, y_train)\n",
        "print(\"Time to train (RandomForests): \")\n",
        "time_rf = time() - t_start\n",
        "y_pred_rf = rf.predict(testing_data)\n",
        "print(\"Accuracy (Random Forests):\", metrics.accuracy_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "t0SJv42N0TWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, according to the training times, the Adaboost algorithm is more efficient that the Random Forest classifier for the Viola and Jones face recognition algorithm."
      ],
      "metadata": {
        "id": "ulfxJwEpGpR1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}